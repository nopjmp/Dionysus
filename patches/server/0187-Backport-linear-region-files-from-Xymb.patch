From 0000000000000000000000000000000000000000 Mon Sep 17 00:00:00 2001
From: Xymb <xymb@endcrystal.me>
Date: Thu, 1 Sep 2022 12:52:01 +1000
Subject: [PATCH] Backport linear region files from Xymb


diff --git a/pom.xml b/pom.xml
index 1f2fc8223808ce352267660ca9a11d7ffec94d70..37259967bb36d70159d8a4ceff1d671aee0bda87 100644
--- a/pom.xml
+++ b/pom.xml
@@ -186,6 +186,11 @@
             <artifactId>zstd-jni</artifactId>
             <version>1.5.2-3</version>
         </dependency>
+        <dependency>
+            <groupId>org.lz4</groupId>
+            <artifactId>lz4-java</artifactId>
+            <version>1.8.0</version>
+        </dependency>
     </dependencies>
 
     <repositories>
diff --git a/src/main/java/dev/pomf/dionysus/DionysusConfig.java b/src/main/java/dev/pomf/dionysus/DionysusConfig.java
index 7cb24e8172f9eb9af1c2903592e21d546c3ebd14..c03b3a66abcf478b8f9ddc140f5d522575d9496c 100644
--- a/src/main/java/dev/pomf/dionysus/DionysusConfig.java
+++ b/src/main/java/dev/pomf/dionysus/DionysusConfig.java
@@ -367,8 +367,18 @@ public class DionysusConfig {
         RegionFile.deflater.setLevel(chunkCompressionLevel);
     }
 
-    public static int maxProcessedBookNBTSize = 8000;
+    public static boolean linearRegionFiles = false;
 
+    private static void linearRegionFiles() {
+        // Set some defaults
+        linearRegionFiles = getBoolean("compression.linear-region-files", linearRegionFiles);
+        setComment("compression.linear-region-files", """
+            Linear region format saves about 50% of disk space in OW and Nether and 95% in The End.
+            For more information: https://github.com/xymb-endcrystalme/LinearRegionFileFormatTools"""
+        );
+    }
+    
+    public static int maxProcessedBookNBTSize = 8000;
     private static void maxProcessedBookNBTSize() {
         maxProcessedBookNBTSize = getInt("max-processed-book-nbt-size", 8000);
     }
diff --git a/src/main/java/dev/pomf/dionysus/util/linear/LinearRegionFile.java b/src/main/java/dev/pomf/dionysus/util/linear/LinearRegionFile.java
new file mode 100644
index 0000000000000000000000000000000000000000..86098abd1de9cc536249e1101ac5783acba95144
--- /dev/null
+++ b/src/main/java/dev/pomf/dionysus/util/linear/LinearRegionFile.java
@@ -0,0 +1,341 @@
+package dev.pomf.dionysus.util.linear;
+
+
+import com.github.luben.zstd.ZstdInputStream;
+import com.github.luben.zstd.ZstdOutputStream;
+import net.jpountz.lz4.LZ4Compressor;
+import net.jpountz.lz4.LZ4Factory;
+import net.jpountz.lz4.LZ4FastDecompressor;
+import net.jpountz.xxhash.XXHashFactory;
+import net.minecraft.server.NBTTagCompound;
+import org.jetbrains.annotations.Nullable;
+
+import java.io.*;
+import java.nio.ByteBuffer;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.StandardCopyOption;
+import java.util.ArrayList;
+
+public class LinearRegionFile extends Thread implements AutoCloseable {
+    private final byte[][] buffer = new byte[32*32][];
+    private final int[] bufferUncompressedSize = new int[32*32];
+    private boolean markedToSave = false;
+    private Object markedToSaveLock = new Object();
+    private boolean close = false;
+    public Path regionFile;
+    final byte COMPRESSION_LEVEL = 1;
+
+    public LinearRegionFile(File file) throws IOException {
+        this(file.toPath());
+    }
+
+    public LinearRegionFile(Path file) throws IOException {
+        this.regionFile = file;
+        File regionFile = new File(this.regionFile.toString());
+
+        LZ4Compressor compressor = LZ4Factory.fastestInstance().fastCompressor();
+        LZ4FastDecompressor decompressor = LZ4Factory.fastestInstance().fastDecompressor();
+
+        for (int i = 0 ; i < 32 * 32 ; i++)
+            this.bufferUncompressedSize[i] = 0;
+
+        if(regionFile.canRead()) {
+            long start = System.nanoTime();
+
+            long fileLength = file.toFile().length();
+            FileInputStream fileStream = new FileInputStream(regionFile);
+            DataInputStream rawDataStream = new DataInputStream(fileStream);
+
+            long SUPERBLOCK = -4323716122432332390L;
+            byte VERSION = 1;
+            int HEADER_SIZE = 32;
+            int FOOTER_SIZE = 8;
+
+            long superBlock = rawDataStream.readLong();
+
+            if (superBlock != SUPERBLOCK) {
+                System.out.println(file);
+                System.out.println("SUPERBLOCK INVALID!");
+                return;
+            }
+
+            byte version = rawDataStream.readByte();
+
+            if (version != VERSION) {
+                System.out.println(file);
+                System.out.println("VERSION INVALID!");
+                return;
+            }
+
+            long newestTimestamp = rawDataStream.readLong();
+            byte compressionLevel = rawDataStream.readByte();
+            short chunkCount = rawDataStream.readShort();
+            int dataCount = rawDataStream.readInt();
+
+            if (fileLength != HEADER_SIZE + dataCount + FOOTER_SIZE) {
+                System.out.println(file);
+                System.out.println("FILE LENGTH INVALID! " + fileLength + " " + (HEADER_SIZE + dataCount + FOOTER_SIZE));
+                return;
+            }
+
+            long dataHash = rawDataStream.readLong();
+            byte[] rawCompressed = new byte[dataCount];
+
+            rawDataStream.readFully(rawCompressed, 0, dataCount);
+
+            superBlock = rawDataStream.readLong();
+
+            if (superBlock != SUPERBLOCK) {
+                System.out.println(file);
+                System.out.println("FOOTER SUPERBLOCK INVALID!");
+                return;
+            }
+
+            DataInputStream dataStream = new DataInputStream(new ZstdInputStream(new ByteArrayInputStream(rawCompressed)));
+
+            int completeDataCount = 0;
+            int total = 4096 * 2;
+            int starts[] = new int[32 * 32];
+            int timestamps[] = new int[32 * 32];
+            for(int i = 0 ; i < 32 * 32 ; i++) {
+                starts[i] = dataStream.readInt();
+                timestamps[i] = dataStream.readInt();
+            }
+
+            for(int i = 0 ; i < 32 * 32 ; i++) {
+                if(starts[i] > 0) {
+                    int size = starts[i];
+                    completeDataCount += size;
+                    byte b[] = new byte[size];
+                    dataStream.readFully(b, 0, size);
+
+                    int maxCompressedLength = compressor.maxCompressedLength(size);
+                    byte[] compressed = new byte[maxCompressedLength];
+                    int compressedLength = compressor.compress(b, 0, size, compressed, 0, maxCompressedLength);
+                    b = new byte[compressedLength];
+                    for(int j = 0 ; j < compressedLength ; j++)
+                        b[j] = compressed[j];
+
+                    this.buffer[i] = b;
+                    this.bufferUncompressedSize[i] = size;
+                }
+            }
+        }
+        this.start();
+    }
+
+    private synchronized void markToSave() {
+        synchronized(markedToSaveLock) {
+            markedToSave = true;
+        }
+    }
+
+    private synchronized boolean isMarkedToSave() {
+        synchronized(markedToSaveLock) {
+            if(markedToSave) {
+                markedToSave = false;
+                return true;
+            }
+            return false;
+        }
+    }
+
+    @Override
+    public void run() {
+        try {
+            while(true) {
+                if(markedToSave) {
+                    try {
+                        flush();
+                    } catch(IOException ex) {
+
+                    }
+                }
+                for(int i = 0 ; i < 100 ; i++) {
+                    Thread.sleep(100);
+                    if(close) {
+                        return;
+                    }
+                }
+            }
+        } catch(InterruptedException ex) {}
+    }
+
+    public synchronized void flush() throws IOException {
+        if(!isMarkedToSave())
+            return;
+
+        long SUPERBLOCK = -4323716122432332390L;
+        byte VERSION = 1;
+        long timestamp = System.currentTimeMillis() / 1000L;
+        short chunkCount = 0;
+
+        File tempFile = new File(regionFile.toString() + ".tmp");
+        FileOutputStream fileStream = new FileOutputStream(tempFile);
+
+        ByteArrayOutputStream zstdByteArray = new ByteArrayOutputStream();
+        ZstdOutputStream zstdStream = new ZstdOutputStream(zstdByteArray, COMPRESSION_LEVEL);
+        zstdStream.setChecksum(true);
+        DataOutputStream zstdDataStream = new DataOutputStream(zstdStream);
+        DataOutputStream dataStream = new DataOutputStream(fileStream);
+
+        dataStream.writeLong(SUPERBLOCK);
+        dataStream.writeByte(VERSION);
+        dataStream.writeLong(timestamp);
+        dataStream.writeByte(COMPRESSION_LEVEL);
+
+        int region_total = 0;
+        int region_raw = 0;
+
+        LZ4FastDecompressor decompressor = LZ4Factory.fastestInstance().fastDecompressor();
+
+        ArrayList<byte[]> byteBuffers = new ArrayList<>();
+        for(int i = 0 ; i < 32 * 32 ; i++) {
+            if(this.bufferUncompressedSize[i] != 0) {
+                chunkCount += 1;
+
+                byte[] content = new byte[bufferUncompressedSize[i]];
+                decompressor.decompress(buffer[i], 0, content, 0, bufferUncompressedSize[i]);
+
+                region_total += buffer[i].length;
+                region_raw += content.length;
+
+                byteBuffers.add(content);
+            } else byteBuffers.add(null);
+        }
+        for(int i = 0 ; i < 32 * 32 ; i++) {
+            zstdDataStream.writeInt(this.bufferUncompressedSize[i]);
+            zstdDataStream.writeInt(0);
+        }
+        for(int i = 0 ; i < 32 * 32 ; i++) {
+            if(byteBuffers.get(i) != null)
+                zstdDataStream.write(byteBuffers.get(i), 0, byteBuffers.get(i).length);
+        }
+        zstdDataStream.close();
+
+        dataStream.writeShort(chunkCount);
+
+        byte[] compressed = zstdByteArray.toByteArray();
+
+        dataStream.writeInt(compressed.length);
+        dataStream.writeLong(XXHashFactory.fastestInstance().hash64().hash(compressed, 0, compressed.length, 0)); // TODO: Hash the contents, not the whole thing
+
+        dataStream.write(compressed, 0, compressed.length);
+        dataStream.writeLong(SUPERBLOCK);
+
+        dataStream.close();
+
+        fileStream.close();
+        Files.move(tempFile.toPath(), this.regionFile, StandardCopyOption.REPLACE_EXISTING);
+    }
+
+    public synchronized void write(int x, int z, ByteBuffer buffer) {
+        LZ4Compressor compressor = LZ4Factory.fastestInstance().fastCompressor();
+        try {
+            byte[] b = toByteArray(new ByteArrayInputStream(buffer.array()));
+            int uncompressedSize = b.length;
+
+            int maxCompressedLength = compressor.maxCompressedLength(b.length);
+            byte[] compressed = new byte[maxCompressedLength];
+            int compressedLength = compressor.compress(b, 0, b.length, compressed, 0, maxCompressedLength);
+            b = new byte[compressedLength];
+            for(int j = 0 ; j < compressedLength ; j++)
+                b[j] = compressed[j];
+
+            this.buffer[getChunkIndex(x, z)] = b;
+            this.bufferUncompressedSize[getChunkIndex(x, z)] = uncompressedSize;
+        } catch (IOException e) {
+
+        }
+
+        markToSave();
+    }
+
+    public DataOutputStream getChunkDataOutputStream(int x, int z) {
+        return new DataOutputStream(new BufferedOutputStream(new LinearRegionFile.ChunkBuffer(x, z)));
+    }
+
+    private class ChunkBuffer extends ByteArrayOutputStream {
+
+        private final int x;
+        private final int z;
+
+        public ChunkBuffer(int x, int z) {
+            super();
+            this.x = x;
+            this.z = z;
+        }
+
+        public void close() throws IOException {
+            ByteBuffer bytebuffer = ByteBuffer.wrap(this.buf, 0, this.count);
+            LinearRegionFile.this.write(x, z, bytebuffer);
+        }
+    }
+
+    private byte[] toByteArray(InputStream in) throws IOException {
+        ByteArrayOutputStream out = new ByteArrayOutputStream();
+        byte[] tempBuffer = new byte[4096];
+
+        int length;
+        while ((length = in.read(tempBuffer)) >= 0) {
+            out.write(tempBuffer, 0, length);
+        }
+
+        return out.toByteArray();
+    }
+
+    @Nullable
+    public synchronized DataInputStream getChunkDataInputStream(int x, int z) {
+        if(this.bufferUncompressedSize[getChunkIndex(x, z)] != 0) {
+            LZ4FastDecompressor decompressor = LZ4Factory.fastestInstance().fastDecompressor();
+            byte[] content = new byte[bufferUncompressedSize[getChunkIndex(x, z)]];
+            decompressor.decompress(this.buffer[getChunkIndex(x, z)], 0, content, 0, bufferUncompressedSize[getChunkIndex(x, z)]);
+            return new DataInputStream(new ByteArrayInputStream(content));
+        }
+        return null;
+    }
+
+    public void clear(int x, int z) {
+        int i = getChunkIndex(x, z);
+        this.buffer[i] = null;
+        this.bufferUncompressedSize[i] = 0;
+        markToSave();
+    }
+
+    public boolean hasChunk(int x, int z) {
+        return this.bufferUncompressedSize[getChunkIndex(x, z)] > 0;
+    }
+
+    @Override
+    public void close() throws IOException {
+        close = true;
+        try {
+            flush();
+        } catch(IOException ex) {
+
+        }
+    }
+
+    private static int getChunkIndex(int x, int z) {
+        return (x & 31) + (z & 31) * 32;
+    }
+
+    public synchronized boolean doesChunkExist(int x, int z) { // STUB
+        return false;
+    }
+
+    boolean recalculateHeader() { // STUB
+        return false;
+    }
+
+    void setOversized(int x, int z, boolean b) {} // STUB
+
+    NBTTagCompound getOversizedData(int x, int z) { // STUB
+        return null;
+    }
+
+    boolean isOversized(int x, int z) { // STUB
+        return false;
+    }
+}
diff --git a/src/main/java/dev/pomf/dionysus/util/linear/LinearRegionFileCache.java b/src/main/java/dev/pomf/dionysus/util/linear/LinearRegionFileCache.java
new file mode 100644
index 0000000000000000000000000000000000000000..b782045a4581d9ffeb42139fcf7a7e3baabdffe7
--- /dev/null
+++ b/src/main/java/dev/pomf/dionysus/util/linear/LinearRegionFileCache.java
@@ -0,0 +1,155 @@
+package dev.pomf.dionysus.util.linear;
+
+import com.destroystokyo.paper.PaperConfig;
+import com.destroystokyo.paper.exception.ServerInternalException;
+import net.minecraft.server.*;
+import org.apache.commons.io.output.NullOutputStream;
+
+import java.io.DataInputStream;
+import java.io.DataOutputStream;
+import java.io.File;
+import java.io.IOException;
+import java.util.Iterator;
+import java.util.LinkedHashMap;
+import java.util.Map;
+
+public class LinearRegionFileCache {
+
+    public static final Map<File, LinearRegionFile> a = new LinkedHashMap<>(PaperConfig.regionFileCacheSize, 0.75f, true); // Spigot - private -> public, Paper - HashMap -> LinkedHashMap
+    public static synchronized LinearRegionFile getRegionFile(File file, int i, int j) { return a(file, i, j); } // Paper - OBFHELPER
+    public static synchronized LinearRegionFile a(File file, int i, int j) {
+        File file1 = new File(file, "region");
+        File file2 = new File(file1, "r." + (i >> 5) + "." + (j >> 5) + ".linear");
+        LinearRegionFile regionfile = LinearRegionFileCache.a.get(file2);
+
+        if (regionfile != null) {
+            return regionfile;
+        } else {
+            if (!file1.exists()) {
+                file1.mkdirs();
+            }
+
+            if (LinearRegionFileCache.a.size() >= PaperConfig.regionFileCacheSize) { // Paper
+                trimCache(); // Paper
+            }
+
+            try {
+                LinearRegionFile regionfile1 = new LinearRegionFile(file2);
+                LinearRegionFileCache.a.put(file2, regionfile1);
+                return regionfile1;
+            } catch (IOException e) {
+                return null;
+            }
+        }
+    }
+
+    public static synchronized LinearRegionFile b(File file, int i, int j) {
+        File file1 = new File(file, "region");
+        File file2 = new File(file1, "r." + (i >> 5) + "." + (j >> 5) + ".linear");
+        LinearRegionFile regionfile = LinearRegionFileCache.a.get(file2);
+
+        if (regionfile != null) {
+            return regionfile;
+        } else if (file1.exists() && file2.exists()) {
+            if (LinearRegionFileCache.a.size() >= 256) {
+                a();
+            }
+
+            try {
+                LinearRegionFile regionfile1 = new LinearRegionFile(file2);
+
+                LinearRegionFileCache.a.put(file2, regionfile1);
+                return regionfile1;
+            } catch (IOException e) {
+                return null;
+            }
+        } else {
+            return null;
+        }
+    }
+
+    // Paper Start
+    private static synchronized void trimCache() {
+        Iterator<Map.Entry<File, LinearRegionFile>> itr = LinearRegionFileCache.a.entrySet().iterator();
+        int count = LinearRegionFileCache.a.size() - PaperConfig.regionFileCacheSize;
+        while (count-- >= 0 && itr.hasNext()) {
+            try {
+                itr.next().getValue().close();
+            } catch (IOException ioexception) {
+                ioexception.printStackTrace();
+                ServerInternalException.reportInternalException(ioexception);
+            }
+            itr.remove();
+        }
+    }
+
+    private static void writeRegion(File file, int x, int z, NBTTagCompound nbttagcompound) throws IOException {
+        LinearRegionFile regionfile = getRegionFile(file, x, z);
+
+        DataOutputStream out = regionfile.getChunkDataOutputStream(x & 31, z & 31);
+        NBTCompressedStreamTools.writeNBT(nbttagcompound, out);
+        out.close();
+        regionfile.setOversized(x, z, false);
+    }
+
+    public static synchronized void a() {
+        for (LinearRegionFile regionfile : LinearRegionFileCache.a.values()) {
+            try {
+                if (regionfile != null) {
+                    regionfile.close();
+                }
+            } catch (IOException ioexception) {
+                ioexception.printStackTrace();
+                ServerInternalException.reportInternalException(ioexception); // Paper
+            }
+        }
+
+        LinearRegionFileCache.a.clear();
+    }
+
+    // CraftBukkit start - call sites hoisted for synchronization
+    public static NBTTagCompound d(File file, int i, int j) throws IOException { // Paper - remove synchronization
+        LinearRegionFile regionfile = a(file, i, j);
+
+        if (regionfile == null) {
+            return null;
+        }
+
+        DataInputStream datainputstream = regionfile.getChunkDataInputStream(i & 31, j & 31);
+
+        if (datainputstream == null) {
+            return null;
+        }
+
+        // NeonPaper start - Handle bad chunks more gracefully
+        try {
+            return NBTCompressedStreamTools.a(datainputstream);
+        } catch (Exception ex) {
+            return null;
+        }
+        // NeonPaper end
+    }
+
+    public static void e(File file, int i, int j, NBTTagCompound nbttagcompound) throws IOException { // Paper - remove synchronization
+        writeRegion(file, i, j, nbttagcompound); // Paper - moved to own method
+        // Paper start
+//      RegionFile regionfile = a(file, i, j);
+//
+//      DataOutputStream dataoutputstream = regionfile.b(i & 31, j & 31);
+//      NBTCompressedStreamTools.a(nbttagcompound, (java.io.DataOutput) dataoutputstream);
+//      dataoutputstream.close();
+        // Paper end
+    }
+    // CraftBukkit end
+
+    public static boolean chunkExists(File file, int i, int j) { // Paper - remove synchronization
+        LinearRegionFile regionfile = b(file, i, j);
+
+        try {
+            return regionfile != null && regionfile.doesChunkExist(i & 31, j & 31);
+        } catch (Exception e) {
+            return false;
+        }
+    }
+    
+}
diff --git a/src/main/java/net/minecraft/server/ChunkRegionLoader.java b/src/main/java/net/minecraft/server/ChunkRegionLoader.java
index f3e1182ac4b953a17209b6edb05cb7a0c3aa3164..56ad82118497acef788a841f16826ef64fc0c53c 100644
--- a/src/main/java/net/minecraft/server/ChunkRegionLoader.java
+++ b/src/main/java/net/minecraft/server/ChunkRegionLoader.java
@@ -13,6 +13,9 @@ import java.util.Map;
 import java.util.Set;
 import javax.annotation.Nullable;
 import java.util.concurrent.ConcurrentLinkedQueue; // Paper
+
+import dev.pomf.dionysus.DionysusConfig;
+import dev.pomf.dionysus.util.linear.LinearRegionFileCache;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 // Spigot start
@@ -70,7 +73,13 @@ public class ChunkRegionLoader implements IChunkLoader, IAsyncChunkSaver {
 
         if (nbttagcompound == null) {
             // CraftBukkit start
-            nbttagcompound = RegionFileCache.d(this.d, i, j);
+            // Dionysus start - Linear Region File
+            if (DionysusConfig.linearRegionFiles) {
+                nbttagcompound = LinearRegionFileCache.d(this.d, i, j);
+            } else {
+                nbttagcompound = RegionFileCache.d(this.d, i, j);
+            }
+            // Dionysus start - Linear Region File
 
             if (nbttagcompound == null) {
                 return null;
@@ -87,7 +96,13 @@ public class ChunkRegionLoader implements IChunkLoader, IAsyncChunkSaver {
         ChunkCoordIntPair chunkcoordintpair = new ChunkCoordIntPair(i, j);
         Supplier<NBTTagCompound> nbttagcompound = this.b.get(chunkcoordintpair); // Spigot
 
-        return nbttagcompound != null ? true : RegionFileCache.chunkExists(this.d, i, j);
+        // Dionysus start - Linear Region File
+        if (DionysusConfig.linearRegionFiles) {
+            return nbttagcompound != null || LinearRegionFileCache.chunkExists(this.d, i, j);
+        } else {
+            return nbttagcompound != null || RegionFileCache.chunkExists(this.d, i, j);
+        }
+        // Dionysus end
     }
 
     // Paper start
@@ -242,7 +257,13 @@ public class ChunkRegionLoader implements IChunkLoader, IAsyncChunkSaver {
 
     private void b(ChunkCoordIntPair chunkcoordintpair, NBTTagCompound nbttagcompound) throws IOException {
         // CraftBukkit start
-        RegionFileCache.e(this.d, chunkcoordintpair.x, chunkcoordintpair.z, nbttagcompound);
+        // Dionysus start - Linear Region File
+        if (DionysusConfig.linearRegionFiles) {
+            LinearRegionFileCache.e(this.d, chunkcoordintpair.x, chunkcoordintpair.z, nbttagcompound);
+        } else {
+            RegionFileCache.e(this.d, chunkcoordintpair.x, chunkcoordintpair.z, nbttagcompound);
+        }
+        // Dionysus end - Linear Region File
 
         /*
         NBTCompressedStreamTools.a(nbttagcompound, (DataOutput) dataoutputstream);
diff --git a/src/main/java/org/bukkit/craftbukkit/CraftServer.java b/src/main/java/org/bukkit/craftbukkit/CraftServer.java
index 697fb7ea48c3b44173208750e9632973a736b446..897df74f5d3a4f56a1a075743bd7ce84566e81b1 100644
--- a/src/main/java/org/bukkit/craftbukkit/CraftServer.java
+++ b/src/main/java/org/bukkit/craftbukkit/CraftServer.java
@@ -23,6 +23,9 @@ import java.util.regex.Pattern;
 
 import javax.imageio.ImageIO;
 
+import dev.pomf.dionysus.DionysusConfig;
+import dev.pomf.dionysus.util.linear.LinearRegionFile;
+import dev.pomf.dionysus.util.linear.LinearRegionFileCache;
 import net.minecraft.server.*;
 
 import org.bukkit.BanList;
@@ -1090,24 +1093,51 @@ public final class CraftServer implements Server {
 
         File parentFolder = world.getWorldFolder().getAbsoluteFile();
 
-        // Synchronized because access to RegionFileCache.a is guarded by this lock.
-        synchronized (RegionFileCache.class) {
-            // RegionFileCache.a should be RegionFileCache.cache
-            Iterator<Map.Entry<File, RegionFile>> i = RegionFileCache.a.entrySet().iterator();
-            while(i.hasNext()) {
-                Map.Entry<File, RegionFile> entry = i.next();
-                File child = entry.getKey().getAbsoluteFile();
-                while (child != null) {
-                    if (child.equals(parentFolder)) {
-                        i.remove();
-                        try {
-                            entry.getValue().c(); // Should be RegionFile.close();
-                        } catch (IOException ex) {
-                            getLogger().log(Level.SEVERE, null, ex);
+        // Dionysus start - Linear Region File // TODO BETTER WAY
+        if (DionysusConfig.linearRegionFiles) {
+            // Synchronized because access to RegionFileCache.a is guarded by this lock.
+            synchronized (LinearRegionFileCache.class) {
+                // RegionFileCache.a should be RegionFileCache.cache
+                Iterator<Map.Entry<File, LinearRegionFile>> i = LinearRegionFileCache.a.entrySet().iterator();
+                while(i.hasNext()) {
+                    Map.Entry<File, LinearRegionFile> entry = i.next();
+                    File child = entry.getKey().getAbsoluteFile();
+                    while (child != null) {
+                        if (child.equals(parentFolder)) {
+                            i.remove();
+                            try {
+                                entry.getValue().close(); // Should be RegionFile.close();
+                            } catch (IOException ex) {
+                                getLogger().log(Level.SEVERE, null, ex);
+                            }
+                            break;
+                        }
+                        child = child.getParentFile();
+                    }
+                }
+            }
+        }
+        // Dionysus end
+        else {
+            // Synchronized because access to RegionFileCache.a is guarded by this lock.
+            synchronized (RegionFileCache.class) {
+                // RegionFileCache.a should be RegionFileCache.cache
+                Iterator<Map.Entry<File, RegionFile>> i = RegionFileCache.a.entrySet().iterator();
+                while(i.hasNext()) {
+                    Map.Entry<File, RegionFile> entry = i.next();
+                    File child = entry.getKey().getAbsoluteFile();
+                    while (child != null) {
+                        if (child.equals(parentFolder)) {
+                            i.remove();
+                            try {
+                                entry.getValue().c(); // Should be RegionFile.close();
+                            } catch (IOException ex) {
+                                getLogger().log(Level.SEVERE, null, ex);
+                            }
+                            break;
                         }
-                        break;
+                        child = child.getParentFile();
                     }
-                    child = child.getParentFile();
                 }
             }
         }
